{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 20:14:27.548569: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-09 20:14:28.803892: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-09 20:14:28.806400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-09 20:14:29.090035: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-09 20:14:29.599783: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as jhimmens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 20:14:44.451888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46339 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2024-07-09 20:14:44.490295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1290 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:1c:00.0, compute capability: 8.6\n",
      "2024-07-09 20:14:44.510288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 4410 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:4f:00.0, compute capability: 8.6\n",
      "2024-07-09 20:14:44.530244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 1546 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:50:00.0, compute capability: 8.6\n",
      "2024-07-09 20:14:44.550259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 35135 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:9c:00.0, compute capability: 8.6\n",
      "2024-07-09 20:14:44.566226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 1290 MB memory:  -> device: 5, name: NVIDIA RTX A6000, pci bus id: 0000:9d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "REPO_PATH = Path.home() / \"workspace/jetpointnet\"\n",
    "SCRIPT_PATH = REPO_PATH / \"python_scripts\"\n",
    "sys.path.append(str(SCRIPT_PATH))\n",
    "\n",
    "from particle import Particle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn import metrics\n",
    "import awkward as ak\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm.auto import tqdm\n",
    "from numpy.lib import recfunctions as rfn\n",
    "from jets_training.models.JetPointNet import PointNetSegmentation\n",
    "from jets_training.jets_train import (\n",
    "    TRAIN_INPUTS,\n",
    "    MAX_SAMPLE_LENGTH,\n",
    "    baseline_configuration,\n",
    "    EXPERIMENT_NAME,\n",
    "    TRAIN\n",
    ")\n",
    "from data_processing.jets.preprocessing_header import NPZ_SAVE_LOC, POINT_TYPE_ENCODING\n",
    "\n",
    "OUTPUT_ACTIVATION_FUNCTION = baseline_configuration['OUTPUT_ACTIVATION_FUNCTION']\n",
    "FRACTIONAL_ENERGY_CUTOFF = baseline_configuration['FRACTIONAL_ENERGY_CUTOFF']\n",
    "OUTPUT_LAYER_SEGMENTATION_CUTOFF = baseline_configuration['OUTPUT_LAYER_SEGMENTATION_CUTOFF']\n",
    "\n",
    "# there is an issue that these are needed\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Suppress the specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "model = PointNetSegmentation(MAX_SAMPLE_LENGTH, \n",
    "                             num_features=len(TRAIN_INPUTS), \n",
    "                             num_classes=1, \n",
    "                             output_activation_function=OUTPUT_ACTIVATION_FUNCTION\n",
    "                             model_version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_NON_FOCAL = True\n",
    "USE_BINARY_ATTRIBUTION_MODEL = True\n",
    "USE_BINARY_ATTRIBUTION_TRUTH = True\n",
    "RENDER_IMAGES = True\n",
    "USE_TRUTH_E = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FILES = 2\n",
    "MAX_WINDOWS = 10 # can take -1 for all\n",
    "\n",
    "NPZ_LOC = NPZ_SAVE_LOC(TRAIN)\n",
    "model_path = \"/home/jhimmens/workspace/jetpointnet/models/rev_2/collected_data/PointNet_best_name=rosy-wood-862.keras\"\n",
    "VISUALIZE_SETS = ['JZ2', 'JZ3', 'JZ4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' PointFeats512/kernel:0': Shape mismatch.The variable shape (1, 1024, 1024), and the assigned value shape (1, 1024, 512) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m HIST_PATH \u001b[38;5;241m=\u001b[39m VISUAL_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m HIST_PATH\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1046\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1044\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     tensor_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 1046\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m       (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot assign value to variable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: Shape mismatch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe variable shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massigned value shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are incompatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1050\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m23\u001b[39m):\n\u001b[1;32m   1052\u001b[0m   \u001b[38;5;66;03m# If the shape is fully defined, we do a runtime check with the shape of\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m   \u001b[38;5;66;03m# value.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' PointFeats512/kernel:0': Shape mismatch.The variable shape (1, 1024, 1024), and the assigned value shape (1, 1024, 512) are incompatible."
     ]
    }
   ],
   "source": [
    "MODEL_NAME = model_path.split('/')[-1]\n",
    "VISUAL_PATH = REPO_PATH / \"visualizations\" / EXPERIMENT_NAME / MODEL_NAME\n",
    "VISUAL_PATH.mkdir(exist_ok=True, parents=True)\n",
    "TRACK_IMAGE_PATH = VISUAL_PATH / \"track_images\"\n",
    "TRACK_IMAGE_PATH.mkdir(exist_ok=True)\n",
    "HIST_PATH = VISUAL_PATH / \"meta_results\"\n",
    "HIST_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "model.load_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Event Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_data_from_npz(npz_file):\n",
    "    all_feats = np.load(npz_file)[\"feats\"]\n",
    "    feats = all_feats[:, :MAX_SAMPLE_LENGTH]  # discard tracking information\n",
    "    frac_labels = all_feats[:, :MAX_SAMPLE_LENGTH][\"truth_cell_fraction_energy\"]\n",
    "    energy_weights = all_feats[:, :MAX_SAMPLE_LENGTH][\"cell_E\"]\n",
    "    return feats, frac_labels, energy_weights\n",
    "\n",
    "metadata_list = []\n",
    "SET_UNDER_INVESTIGATION = 'val'\n",
    "\n",
    "for set_name in VISUALIZE_SETS:\n",
    "    images_rendered = 0\n",
    "    for file_idx, data_file in enumerate(glob.glob(os.path.join(NPZ_LOC / SET_UNDER_INVESTIGATION / set_name, \"*.npz\"))):\n",
    "        if file_idx >= MAX_FILES:\n",
    "            break\n",
    "        filename_npz = data_file\n",
    "        feats, fractional_energy, total_cell_energy = load_data_from_npz(filename_npz)\n",
    "\n",
    "        filtered_features = feats[TRAIN_INPUTS]\n",
    "\n",
    "        unstructured_filtered_features = rfn.structured_to_unstructured(filtered_features)\n",
    "\n",
    "        # get prediction\n",
    "        model_results = model.predict(unstructured_filtered_features)\n",
    "\n",
    "        # image creation loop\n",
    "        for window_index, window in enumerate(feats):\n",
    "\n",
    "            name = f'Focal Track - ID: {window[0][\"track_ID\"]}' # add PDGID name??\n",
    "\n",
    "            focus_hit_x = []\n",
    "            focus_hit_y = []\n",
    "            focus_hit_z = []\n",
    "\n",
    "            cell_x_list = []\n",
    "            cell_y_list = []\n",
    "            cell_z_list = []\n",
    "            cell_model_attribution = []\n",
    "            cell_truth_attribution = []\n",
    "            cell_total_energy = []\n",
    "\n",
    "            non_focus_tracks = {}\n",
    "            delta_r_dict = {}\n",
    "            pt_dict = {}\n",
    "\n",
    "            for point_index, point in enumerate(window):\n",
    "                # this would be much nicer as a match-case statement, but it kept giving me issues\n",
    "                if point['category'] == POINT_TYPE_ENCODING[\"focus hit\"]:\n",
    "                    focus_hit_x.append(point[\"normalized_x\"])\n",
    "                    focus_hit_y.append(point[\"normalized_y\"])\n",
    "                    focus_hit_z.append(point[\"normalized_z\"])\n",
    "                elif point['category'] == POINT_TYPE_ENCODING[\"cell\"]:\n",
    "                    cell_x_list.append(point[\"normalized_x\"])\n",
    "                    cell_y_list.append(point[\"normalized_y\"])\n",
    "                    cell_z_list.append(point[\"normalized_z\"])\n",
    "                    cell_total_energy.append(point[\"cell_E\"])\n",
    "                    if USE_BINARY_ATTRIBUTION_MODEL:\n",
    "                        cell_model_attribution.append(int(model_results[window_index][point_index] >= OUTPUT_LAYER_SEGMENTATION_CUTOFF))\n",
    "                    else:\n",
    "                        cell_model_attribution.append(model_results[window_index][point_index])\n",
    "                    if USE_BINARY_ATTRIBUTION_TRUTH:\n",
    "                        cell_truth_attribution.append(int(fractional_energy[window_index][point_index] >= FRACTIONAL_ENERGY_CUTOFF))\n",
    "                    else:\n",
    "                        cell_truth_attribution.append(fractional_energy[window_index][point_index])\n",
    "                elif point['category'] == POINT_TYPE_ENCODING[\"unfocus hit\"]:\n",
    "                    if point['track_ID'] in non_focus_tracks:\n",
    "                        non_focus_tracks[point['track_ID']]['non_focus_hit_x'].append(point[\"normalized_x\"])\n",
    "                        non_focus_tracks[point['track_ID']]['non_focus_hit_y'].append(point[\"normalized_y\"])\n",
    "                        non_focus_tracks[point['track_ID']]['non_focus_hit_z'].append(point[\"normalized_z\"])\n",
    "                    else:\n",
    "                        non_focus_tracks[point['track_ID']] = {\n",
    "                            'non_focus_hit_x': [point[\"normalized_x\"]],\n",
    "                            'non_focus_hit_y': [point[\"normalized_y\"]],\n",
    "                            'non_focus_hit_z': [point[\"normalized_z\"]],\n",
    "                            'non_focus_pt': point[\"track_pt\"],\n",
    "                            'delta_R': point[\"delta_R\"],\n",
    "                        }\n",
    "                elif point['category'] == POINT_TYPE_ENCODING[\"padding\"]:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise Exception(\"Unknown point in npz files!\")\n",
    "\n",
    "            cell_truth_attribution = np.array(cell_truth_attribution)\n",
    "            cell_model_attribution = np.array(cell_model_attribution)\n",
    "\n",
    "            nCells = len(cell_x_list)\n",
    "\n",
    "            y_true = (cell_truth_attribution == 1).astype(np.float32)\n",
    "            y_pred = (cell_model_attribution == 1).astype(np.float32)\n",
    "\n",
    "            tp = np.sum((cell_model_attribution == 1) & (cell_truth_attribution == 1))\n",
    "            fp = np.sum((cell_model_attribution == 1) & (cell_truth_attribution == 0))\n",
    "            tn = np.sum((cell_model_attribution == 0) & (cell_truth_attribution == 0))\n",
    "            fn = np.sum((cell_model_attribution == 0) & (cell_truth_attribution == 1))\n",
    "            positive = np.sum(cell_truth_attribution == 1)\n",
    "            negative = np.sum(cell_truth_attribution == 0)\n",
    "            predicted_positive = np.sum(cell_model_attribution == 1)\n",
    "            predicted_negative = np.sum(cell_model_attribution == 0)\n",
    "\n",
    "            valid_cell_mask = window['category'] == 1\n",
    "\n",
    "            activated_energy = np.sum(window['cell_E'][valid_cell_mask][(cell_model_attribution == 1)])\n",
    "            ideal_activation_energy = np.sum(window['cell_E'][valid_cell_mask][(cell_truth_attribution == 1)])\n",
    "            total_truth_track_energy = np.sum(window[\"truth_cell_total_energy\"][valid_cell_mask] * window[\"truth_cell_fraction_energy\"][valid_cell_mask])\n",
    "            \n",
    "            average_energy = np.mean(window[\"cell_E\"])\n",
    "            average_truth_energy = np.mean(window[\"truth_cell_total_energy\"][valid_cell_mask] * window[\"truth_cell_fraction_energy\"][valid_cell_mask])\n",
    "\n",
    "            #tp_rate_partial = tp / n_postive_true_hits\n",
    "            #fp_rate_partial = fp / nCells\n",
    "            #tn_rate_partial = tn / n_negative_true_hits\n",
    "            #fn_rate_partial = fn / nCells\n",
    "\n",
    "            track_information = {\n",
    "                'set_name': set_name,\n",
    "                'track_ID': window['track_ID'][0],\n",
    "                'total_truth_track_E': np.sum(window[\"truth_cell_total_energy\"][valid_cell_mask] * window[\"truth_cell_fraction_energy\"][valid_cell_mask]),\n",
    "                'total_real_E': np.sum(window[\"cell_E\"][valid_cell_mask]),\n",
    "                'track_pt': window['track_pt'][0],\n",
    "                'total_truth_energy': total_truth_track_energy,\n",
    "                'activated_energy': activated_energy,\n",
    "                'ideal_activation_energy': ideal_activation_energy,\n",
    "                'truth_attributions': positive,\n",
    "                'rate_truth_activations': np.sum(cell_truth_attribution == 1)/nCells,\n",
    "                'model_attributions': predicted_positive,\n",
    "                'n_non_focal_tracks': len(non_focus_tracks),\n",
    "                'n_cells': nCells,\n",
    "                'num_correct_predictions': np.sum(cell_truth_attribution == cell_model_attribution),\n",
    "                'dumb_accuracy': max(positive, negative)/nCells,\n",
    "                'positive_dumb_accuracy': positive/nCells,\n",
    "                'negative_dumb_accuracy': negative/nCells,\n",
    "                'accuracy': np.sum(cell_truth_attribution == cell_model_attribution)/nCells,\n",
    "                'average_energy': average_energy,\n",
    "                'average_truth_energy': average_truth_energy,\n",
    "                # see https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "                'num_false_positives': fp,\n",
    "                'num_false_negatives': fn,\n",
    "                'num_true_positives': tp,\n",
    "                'num_true_negatives': tn,\n",
    "                # for the 4 below, manual implementation has a much faster run time\n",
    "                'precision_score': metrics.precision_score(y_true, y_pred),\n",
    "                'recall_score': metrics.recall_score(y_true, y_pred),\n",
    "                'f1_score': metrics.f1_score(y_true, y_pred),\n",
    "                'hamming_loss': metrics.hamming_loss(y_true, y_pred),\n",
    "                # assorted, less useful stats, could delete?\n",
    "                'false_positive_rate': fp/negative if negative != 0 else 0,\n",
    "                'false_negative_rate': fn/positive if positive != 0 else 0,\n",
    "                'true_positive_rate': tp/positive if positive != 0 else 0,\n",
    "                'true_negative_rate': tn/negative if negative != 0 else 0,\n",
    "                'positive_predictive_value': tp/predicted_positive if predicted_positive != 0 else 0,\n",
    "                'false_discovery_rate': fp/predicted_positive if predicted_positive != 0 else 0,\n",
    "                'false_omission_rate': fn/predicted_negative if predicted_negative != 0 else 0,\n",
    "                'negative_predictive_value': tn/predicted_negative if predicted_negative != 0 else 0,\n",
    "                'threat_score': tp/(tp+fn+fp) if tp+fn+fp != 0 else 0,\n",
    "                #potential to add data from awk files like PDG ID, Chi^2/dof\n",
    "            }\n",
    "\n",
    "            # model performace\n",
    "\n",
    "            metadata_list.append(track_information)\n",
    "\n",
    "            if (RENDER_IMAGES and (MAX_WINDOWS == -1 or images_rendered < MAX_WINDOWS)) or nCells > 1000:\n",
    "                images_rendered += 1\n",
    "                # convert to plot:\n",
    "                fig = plt.figure(figsize=(22, 7))\n",
    "                fig.suptitle(f'Set: {set_name}, Accuracy factor: {np.sum(cell_truth_attribution == cell_model_attribution)/max(positive, negative):.2f}, Event: {window[0][\"event_number\"]} Track: {window[0][\"track_ID\"]}, $\\sum E={sum(cell_total_energy):.2f}$, nCells={len(cell_x_list)}, pt={window[\"track_pt\"][0]:.2f}, activated_energy: {float(activated_energy):.4f}, ideal_activation_energy: {ideal_activation_energy:.4f}, truth track E: {total_truth_track_energy:.5f}')\n",
    "\n",
    "                ax1 = fig.add_subplot(131, projection='3d')\n",
    "                ax2 = fig.add_subplot(132, projection='3d')\n",
    "                ax3 = fig.add_subplot(133, projection='3d')\n",
    "\n",
    "                ax_list = [ax1, ax2, ax3]\n",
    "\n",
    "                for ax_i in ax_list:\n",
    "                    ax_i.plot(focus_hit_x, focus_hit_y, focus_hit_z, label=name)\n",
    "                    if PLOT_NON_FOCAL:\n",
    "                        for non_focal_id, non_focal_track in non_focus_tracks.items():\n",
    "                            ax_i.plot(non_focal_track['non_focus_hit_x'],\n",
    "                                    non_focal_track['non_focus_hit_y'], \n",
    "                                    non_focal_track['non_focus_hit_z'], \n",
    "                                    label=f\"Non Focal - ID: {non_focal_id}\")\n",
    "                        ax_i.legend()\n",
    "                    ax_i.set_xlabel('X Coordinate (mm)')\n",
    "                    ax_i.set_ylabel('Y Coordinate (mm)')\n",
    "                    ax_i.set_zlabel('Z Coordinate (mm)')\n",
    "\n",
    "                # First subplot\n",
    "                ax1.set_title(f'Model Prediction - {np.sum(cell_model_attribution)} activations')\n",
    "                sc1 = ax1.scatter(cell_x_list, cell_y_list, cell_z_list, c=cell_model_attribution, cmap='jet', vmin=0, vmax=1)\n",
    "                cbar1 = plt.colorbar(sc1, ax=ax1)\n",
    "                cbar1.set_label('Model Output')\n",
    "                \n",
    "                # Second subplot\n",
    "                ax2.set_title(f'Truth Values - {np.sum(cell_truth_attribution)} activations')\n",
    "                sc2 = ax2.scatter(cell_x_list, cell_y_list, cell_z_list, c=cell_truth_attribution, cmap='jet', vmin=0, vmax=1)\n",
    "                cbar2 = plt.colorbar(sc2, ax=ax2)\n",
    "                cbar2.set_label('frac_E')\n",
    "                \n",
    "                # Third subplot, total energies\n",
    "\n",
    "                if USE_TRUTH_E:\n",
    "                    ax3.set_title(f'Cell Energies (Truth)')\n",
    "                else:\n",
    "                    ax3.set_title(f'Cell Energies (Not Truth)')\n",
    "                cell_x_array_np = np.array(cell_x_list)\n",
    "                cell_y_array_np = np.array(cell_y_list)\n",
    "                cell_z_array_np = np.array(cell_z_list)\n",
    "                cell_total_energy_array = np.array(cell_total_energy)\n",
    "\n",
    "                mask = np.array(cell_total_energy) > 0\n",
    "\n",
    "                # Ensure normalization is consistent with LogNorm only for positive values\n",
    "                if np.any(mask):\n",
    "                    sc3 = ax3.scatter(cell_x_array_np[mask], cell_y_array_np[mask], cell_z_array_np[mask], c=cell_total_energy_array[mask], cmap='jet', norm=LogNorm())\n",
    "                else:\n",
    "                    sc3 = ax3.scatter(cell_x_array_np, cell_y_array_np, cell_z_array_np, cmap='jet')\n",
    "\n",
    "                cbar3 = plt.colorbar(sc3, ax=ax3)\n",
    "                cbar3.set_label('Total_Label (MeV)')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                print(f\"saving: event={window[0]['event_number']:09}_track={window[0]['track_ID']:03}\")\n",
    "                SET_IMAGE_PATH = TRACK_IMAGE_PATH / set_name\n",
    "                SET_IMAGE_PATH.mkdir(exist_ok=True)\n",
    "                plt.savefig(SET_IMAGE_PATH / f\"event={window[0]['event_number']:09}_track={window[0]['track_ID']:03}.png\")\n",
    "                plt.close()\n",
    "            \n",
    "metadata = pd.DataFrame(metadata_list)\n",
    "metadata.to_csv(HIST_PATH / \"metadata.csv\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed, load the metadata info from a csv file, if you ran the above cells this is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "metadata_left = pd.read_csv(HIST_PATH / \"metadata.csv\")\n",
    "metadata_right = pd.read_csv(HIST_PATH / \"metadata.csv\")\n",
    "from_csv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the genorated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if False:\n",
    "        left_sets = ['JZ2']\n",
    "        right_sets = ['JZ3']\n",
    "\n",
    "        if not from_csv:\n",
    "                if not set(left_sets).issubset(set(VISUALIZE_SETS)):\n",
    "                        raise ValueError(f\"left_sets is not a subset of VISUALIZE_SETS\")\n",
    "\n",
    "                if not set(right_sets).issubset(set(VISUALIZE_SETS)):\n",
    "                        raise ValueError(f\"right_sets is not a subset of VISUALIZE_SETS\")\n",
    "\n",
    "        # Filter the data for LEFT and RIGHT\n",
    "        metadata_left = metadata[metadata['set_name'].isin(left_sets)]\n",
    "        metadata_right = metadata[metadata['set_name'].isin(right_sets)]\n",
    "left_description = '6M params, JZ 2 3 4' # ' '.join(left_sets)\n",
    "right_description = '6M params, JZ 2 3 4' # ' '.join(right_sets)\n",
    "left_n_events = len(metadata_left)\n",
    "right_n_events = len(metadata_right)\n",
    "\n",
    "FIG_SIZE=(15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def calc_f1_score(metadata, set_description):\n",
    "    tp_masked = sum(np.array(metadata['num_true_positives']))\n",
    "    fp_masked = sum(np.array(metadata['num_false_positives']))\n",
    "    # tn_masked = sum(np.array(metadata['num_true_negatives']))\n",
    "    fn_masked = sum(np.array(metadata['num_false_negatives']))\n",
    "    print(f\"F1 score ({set_description}): {(2 * tp_masked)/(2*tp_masked+fp_masked+fn_masked):.2f}\")\n",
    "\n",
    "calc_f1_score(metadata_left, left_description)\n",
    "calc_f1_score(metadata_right, right_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_data = 'track_pt'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle('Focal Track pt')\n",
    "\n",
    "# Plot for LEFT\n",
    "axs[0].hist(metadata_left[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[0].set_title(f'{left_description} - nEvents = {left_n_events}')\n",
    "axs[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel(plot_data)\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot for RIGHT\n",
    "axs[1].hist(metadata_right[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[1].set_title(f'{right_description} - nEvents = {right_n_events}')\n",
    "axs[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(plot_data)\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plot_data = 'n_cells'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"Event Cells\")\n",
    "# Plot for LEFT\n",
    "axs[0].hist(metadata_left[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[0].set_title(f'{left_description} - nEvents = {left_n_events}')\n",
    "axs[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel(plot_data)\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot for RIGHT\n",
    "axs[1].hist(metadata_right[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[1].set_title(f'{right_description} - nEvents = {right_n_events}')\n",
    "axs[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(plot_data)\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"Truth v Model Activation\")\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left['truth_attributions'], metadata_left['model_attributions'], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel('Truth activations')\n",
    "axs[0].set_ylabel('Model activations')\n",
    "#axs[0].colorbar(label='Counts')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right['truth_attributions'], metadata_right['model_attributions'], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel('Truth activations')\n",
    "axs[1].set_ylabel('Model activations')\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_data = 'n_cells'\n",
    "y_data = 'model_attributions'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"nCells vs nActivations\")\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left[x_data], metadata_left[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel(x_data)\n",
    "axs[0].set_ylabel(y_data)\n",
    "#axs[0].colorbar(label='Counts')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right[x_data], metadata_right[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel(x_data)\n",
    "axs[1].set_ylabel(y_data)\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_data = 'activated_energy'\n",
    "y_data = 'total_truth_energy'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"Activated Energy vs Total Truth Event Energy\")\n",
    "\n",
    "x_bins_left = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[x_data])), 50)\n",
    "y_bins_left = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[y_data])), 50)\n",
    "\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left[x_data], metadata_left[y_data], bins=[x_bins_left, y_bins_left], cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel(x_data)\n",
    "axs[0].set_ylabel(y_data)\n",
    "axs[0].set_xlim([0.1, np.max(metadata_left[x_data])])\n",
    "axs[0].set_ylim([0.1, np.max(metadata_left[y_data])])\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "x_bins_right = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[x_data])), 50)\n",
    "y_bins_right = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[y_data])), 50)\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right[x_data], metadata_right[y_data], bins=[x_bins_right, y_bins_right], cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel(x_data)\n",
    "axs[1].set_ylabel(y_data)\n",
    "axs[1].set_xlim([0.1, np.max(metadata_right[x_data])])\n",
    "axs[1].set_ylim([0.1, np.max(metadata_right[y_data])])\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_data = 'activated_energy'\n",
    "y_data = 'total_truth_track_E'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"Activated Energy vs Total Truth Focal Track Energy\")\n",
    "x_bins_left = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[x_data])), 50)\n",
    "y_bins_left = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[y_data])), 50)\n",
    "\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left[x_data], metadata_left[y_data], bins=[x_bins_left, y_bins_left], cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel(x_data)\n",
    "axs[0].set_ylabel(y_data)\n",
    "axs[0].set_xlim([0.1, np.max(metadata_left[x_data])])\n",
    "axs[0].set_ylim([0.1, np.max(metadata_left[y_data])])\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "x_bins_right = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[x_data])), 50)\n",
    "y_bins_right = np.logspace(np.log10(1e-6), np.log10(np.max(metadata_right[y_data])), 50)\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right[x_data], metadata_right[y_data], bins=[x_bins_right, y_bins_right], cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel(x_data)\n",
    "axs[1].set_ylabel(y_data)\n",
    "axs[1].set_xlim([0.1, np.max(metadata_right[x_data])])\n",
    "axs[1].set_ylim([0.1, np.max(metadata_right[y_data])])\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_data = 'dumb_accuracy'\n",
    "y_data = 'accuracy'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"nDumb Activations to nTruth Activations\")\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left[x_data], metadata_left[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel(x_data)\n",
    "axs[0].set_ylabel(y_data)\n",
    "#axs[0].colorbar(label='Counts')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right[x_data], metadata_right[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel(x_data)\n",
    "axs[1].set_ylabel(y_data)\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mspawn ENOTCONN. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_data = 'negative_dumb_accuracy'\n",
    "y_data = 'accuracy'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle(\"nNegativeDumb Activations to nTruth Activations\")\n",
    "# Plot for LEFT\n",
    "_, _, _, im_left = axs[0].hist2d(metadata_left[x_data], metadata_left[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[0].set_title(f'{left_description} - nEvents={left_n_events}')\n",
    "axs[0].set_xlabel(x_data)\n",
    "axs[0].set_ylabel(y_data)\n",
    "#axs[0].colorbar(label='Counts')\n",
    "fig.colorbar(im_left, ax=axs[0], label='Counts')\n",
    "\n",
    "# Plot for RIGHT\n",
    "_, _, _, im_right = axs[1].hist2d(metadata_right[x_data], metadata_right[y_data], bins=50, cmap='viridis', norm=LogNorm())\n",
    "axs[1].set_title(f'{right_description} - nEvents={right_n_events}')\n",
    "axs[1].set_xlabel(x_data)\n",
    "axs[1].set_ylabel(y_data)\n",
    "fig.colorbar(im_right, ax=axs[1], label='Counts')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = 'f1_score'\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=FIG_SIZE)\n",
    "fig.suptitle('Event F1 Score')\n",
    "\n",
    "# Plot for LEFT\n",
    "axs[0].hist(metadata_left[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[0].set_title(f'{left_description} - nEvents = {left_n_events}')\n",
    "axs[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel(plot_data)\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot for RIGHT\n",
    "axs[1].hist(metadata_right[plot_data], bins=50, label=\"track_pt\")\n",
    "axs[1].set_title(f'{right_description} - nEvents = {right_n_events}')\n",
    "axs[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(plot_data)\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
